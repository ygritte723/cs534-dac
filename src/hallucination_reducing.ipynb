{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "os.umask(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_description = 'a red apple'\n",
    "\n",
    "input_text = f\"short: please describe what you might see in a picture of a scene that contains 'a Christmas tree', write each sentence in a list, and use complete sentences with all nouns and objects you are referring to\\n \\\n",
    "                  long: \t1\tIn the center of the room, a majestic evergreen Christmas tree stands tall, adorned with twinkling lights and colorful ornaments.\\n \\\n",
    "            2\tDelicate strands of tinsel gracefully drape the tree's branches, adding a touch of shimmer to the festive display.\\n \\\n",
    "            3\tAn elegant star or angel graces the top of the tree, representing the Star of Bethlehem or the heavenly messengers present at Jesus' birth.\\n \\\n",
    "            4\tWrapped presents in various shapes and sizes are piled beneath the tree, their festive gift wrap and bows hinting at the surprises inside.\\n \\\n",
    "            5\tA cozy fireplace crackles nearby, with stockings hung from the mantel, eagerly awaiting the arrival of Santa Claus.\\n \\\n",
    "            6\tLush green garlands and flickering candles decorate the mantel, enhancing the holiday atmosphere.\\n \\\n",
    "            7\tComfortable seating arrangements, such as sofas and armchairs, are positioned near the tree, complete with plush cushions and warm throw blankets.\\n \\\n",
    "            8\tFamily members and friends gather around the tree in festive attire, sharing laughter and conversation.\\n \\\n",
    "            9\tA beautifully crafted wreath hangs on a nearby wall or window, adding an additional touch of holiday cheer.\\n \\\n",
    "            10\tThrough the window, a snowy winter landscape can be seen, with snow-covered trees, rooftops, and gently falling snowflakes, creating the perfect backdrop for the Christmas scene.\\n \\\n",
    "                  short: please describe what you might see in a picture of a scene that contains 'a male hand playing nervously with a pencil on a black background', write each sentence in a list, and use complete sentences with all nouns and objects you are referring to \\n \\\n",
    "                  long:   1\tA male hand is positioned prominently in the frame, with fingers flexing and shifting as they manipulate a pencil.\\n \\\n",
    "            2\tThe pencil, held between the thumb and index finger, twirls and spins as the hand moves it nervously.\\n \\\n",
    "            3\tShadows from the hand and pencil cast dramatic patterns on the stark black background, emphasizing the sense of tension and unease.\\n \\\n",
    "            4\tFlecks of graphite from the pencil's tip may be visible, scattered across the black surface, as a result of the restless movements.\\n \\\n",
    "            5\tThe hand's knuckles and veins are accentuated by the lighting, highlighting the pressure and force exerted during the fidgeting.\\n \\\n",
    "            6\tThe pencil's eraser end, worn and discolored, suggests frequent use and a history of anxious behavior.\\n \\\n",
    "            7\tA hint of perspiration on the hand's skin glistens under the light, further revealing the nervous energy within the scene.\\n \\\n",
    "            8\tThe positioning of the hand, perhaps slightly off-center or at an angle, contributes to the visual tension of the composition.\\n \\\n",
    "            9\tFingernails on the hand may appear bitten or worn, indicating a habit of nervousness and stress.\\n \\\n",
    "            10\tThe black background contrasts sharply with the hand and pencil, isolating them in the scene and focusing the viewer's attention on the restless, uneasy motion.\\n \\\n",
    "                  short: please describe what you might see in a picture of a scene that contains 'a man is programming', write each sentence in a list, and use complete sentences with all nouns and objects you are referring to \\n \\\n",
    "                  long:   1\tA focused man sits at a desk, his eyes intently scanning the computer screen in front of him as he works on a programming project.\\n \\\n",
    "            2\tThe computer display is filled with lines of code, featuring various colors and syntax highlighting to differentiate between elements of the programming language.\\n \\\n",
    "            3\tThe man's fingers move swiftly and confidently across the keyboard, typing commands and adjusting the code as needed.\\n \\\n",
    "            4\tBeside the keyboard, a mouse and a notepad with handwritten notes or algorithms offer additional tools for the programmer's work.\\n \\\n",
    "            5\tA cup of coffee or tea sits nearby, providing the man with a source of caffeine to maintain his focus and energy.\\n \\\n",
    "            6\tThe room's lighting, either from a desk lamp or overhead lights, illuminates the workspace, creating a comfortable environment for concentration.\\n \\\n",
    "            7\tThe man wears casual attire, such as a t-shirt and jeans, reflecting the informal nature of the programming process.\\n \\\n",
    "            8\tReference books or technical manuals may be stacked or spread out on the desk, offering guidance and information for the programmer.\\n \\\n",
    "            9\tThe man's facial expression, furrowed brows or a slight frown, conveys his deep concentration and determination to solve the coding challenge at hand.\\n \\\n",
    "            10\tSurrounding the man, other electronic devices, like a smartphone or tablet, may be present, indicating the interconnected nature of his work in the digital realm.\\n \\\n",
    "                  short: please describe what you might see in a picture of a scene that contains '{short_description}', write each sentence in a list, and use complete sentences with all nouns and objects you are referring to \\n \\\n",
    "                  long: \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1\tA red apple sits on a white plate in a festive Christmas scene shot from above.\n",
      "             2\tThe apple's shape is reminiscent of the classic red apple, shaped and dusted by the camera lens.\n",
      "             3\tThe apple's red color glistens in the bright light, emphasized by the white plate and clear dishes\n",
      "GPTNeoConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-2.7B\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      16\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2560,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 20,\n",
      "  \"num_layers\": 32,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# original generator\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B', device=0)\n",
    "\n",
    "res = generator(input_text, do_sample=True, max_length=len(input_text.split()) + 800,\n",
    "                          min_length=len(input_text.split()) + 600)\n",
    "long_description_out = res[0]['generated_text'].replace(input_text, \"\")\n",
    "print(long_description_out)\n",
    "print(generator.model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xzhon54/miniconda3/envs/new_env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/xzhon54/miniconda3/envs/new_env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Generated Text:\n",
      " 1   A red apple sits on a table, surrounded by a variety of other fruits and vegetables.\n",
      "2   In the center, a red apple is placed on a plate, surrounded with other fruits, vegetables, and other foods.\n",
      "3   The apple is surrounded by other fruits.\n",
      "4   Other fruits surround the apple.\n",
      "5   Fruits surround the red apple.\n"
     ]
    }
   ],
   "source": [
    "# generator with hallucination-reducing parameters\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Input prompt\n",
    "prompt = input_text\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "# Generate text with hallucination-reducing parameters\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=200,  # Generate up to 200 new tokens\n",
    "    min_new_tokens=50,  # Generate at least 50 new tokens\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.7, # Controls the randomness of token sampling.\n",
    "    top_k=50, # Limits sampling to the top-k tokens with the highest probabilities.\n",
    "    top_p=0.9, # Includes only the smallest set of tokens whose cumulative probability exceeds p.\n",
    "    repetition_penalty=1.2, # Penalize repeated phrases\n",
    "    no_repeat_ngram_size=3, # Prevent repeated bigrams\n",
    ")\n",
    "\n",
    "# # Decode and print the result\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "# Remove the input prompt from the output if necessary\n",
    "if generated_text.startswith(input_text):\n",
    "    generated_text = generated_text[len(input_text):].strip()\n",
    "\n",
    "print(\"Raw Generated Text:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight semantic similarity model\n",
    "\n",
    "def filter_hallucinations(input_text, expanded_text, min_similarity=0.7):\n",
    "    \"\"\"\n",
    "    Filter hallucinated sentences by checking semantic similarity with the input context.\n",
    "    \"\"\"\n",
    "    input_embedding = similarity_model.encode(input_text, convert_to_tensor=True)\n",
    "    sentences = expanded_text.split(\"\\n\")\n",
    "    filtered_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence.strip():  # Ignore empty sentences\n",
    "            sentence_embedding = similarity_model.encode(sentence, convert_to_tensor=True)\n",
    "            similarity = util.pytorch_cos_sim(input_embedding, sentence_embedding).item()\n",
    "            if similarity >= min_similarity:\n",
    "                filtered_sentences.append(sentence)\n",
    "\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Generated Text:\n",
      " 1   A red apple sits on a table, surrounded by a variety of other fruits and vegetables.\n",
      "2   In the center, a red apple is placed on a plate, surrounded with other fruits, vegetables, and other foods.\n",
      "3   The apple is surrounded by other fruits.\n",
      "4   Other fruits surround the apple.\n",
      "5   Fruits surround the red apple.\n",
      "\n",
      "Filtered Sentences (Reduced Hallucination):\n",
      " ['1   A red apple sits on a table, surrounded by a variety of other fruits and vegetables.', '5   Fruits surround the red apple.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Generated Text:\\n\", generated_text)\n",
    "filtered_sentences = filter_hallucinations(short_description, generated_text, 0.7)\n",
    "print(\"\\nFiltered Sentences (Reduced Hallucination):\\n\", filtered_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
