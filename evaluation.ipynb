{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dac/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from open_clip import create_model_and_transforms\n",
    "from open_clip import tokenize \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"correct_test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>positive</th>\n",
       "      <th>neg1</th>\n",
       "      <th>neg2</th>\n",
       "      <th>neg3</th>\n",
       "      <th>neg4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perspiring_59.jpg</td>\n",
       "      <td>a woman is holding a dumbbell in her hand</td>\n",
       "      <td>a woman is looking at a dumbbell in her hand</td>\n",
       "      <td>a woman is holdgrowing ong a dumbbell growing ...</td>\n",
       "      <td>a woman is holding a banana in her hand</td>\n",
       "      <td>a dancer is holding a dumbbell in her hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2409207.jpg</td>\n",
       "      <td>a group of sheep in a field behind a wire fence</td>\n",
       "      <td>a group of sheep in a field wearing a wire fence</td>\n",
       "      <td>a group with sheep in a field behind a wire fence</td>\n",
       "      <td>a group of sheep in a herd behind a wire fence</td>\n",
       "      <td>a group of sheep in a field under a wire fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2371196.jpg</td>\n",
       "      <td>a cat sitting on top of a television</td>\n",
       "      <td>a cat sitting using top of a televisiusing</td>\n",
       "      <td>a cat sitting standing on top of a televisista...</td>\n",
       "      <td>a cat sitting on side of a television</td>\n",
       "      <td>a woman sitting on top of a television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2384379.jpg</td>\n",
       "      <td>a person standing on skis in the snow</td>\n",
       "      <td>a pershas standing has skis in the snow</td>\n",
       "      <td>a perslooking at standing looking at skis in t...</td>\n",
       "      <td>a person standing on top in the snow</td>\n",
       "      <td>a person walking on skis in the snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357958.jpg</td>\n",
       "      <td>a man riding a wave on a surfboard</td>\n",
       "      <td>a man riding a wave lying on a surfboard</td>\n",
       "      <td>a man riding a wave under a surfboard</td>\n",
       "      <td>a man riding a wave off a surfboard</td>\n",
       "      <td>a man riding a bicycle on a surfboard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image                                         positive  \\\n",
       "0  perspiring_59.jpg        a woman is holding a dumbbell in her hand   \n",
       "1        2409207.jpg  a group of sheep in a field behind a wire fence   \n",
       "2        2371196.jpg             a cat sitting on top of a television   \n",
       "3        2384379.jpg            a person standing on skis in the snow   \n",
       "4        2357958.jpg               a man riding a wave on a surfboard   \n",
       "\n",
       "                                               neg1  \\\n",
       "0      a woman is looking at a dumbbell in her hand   \n",
       "1  a group of sheep in a field wearing a wire fence   \n",
       "2        a cat sitting using top of a televisiusing   \n",
       "3           a pershas standing has skis in the snow   \n",
       "4          a man riding a wave lying on a surfboard   \n",
       "\n",
       "                                                neg2  \\\n",
       "0  a woman is holdgrowing ong a dumbbell growing ...   \n",
       "1  a group with sheep in a field behind a wire fence   \n",
       "2  a cat sitting standing on top of a televisista...   \n",
       "3  a perslooking at standing looking at skis in t...   \n",
       "4              a man riding a wave under a surfboard   \n",
       "\n",
       "                                             neg3  \\\n",
       "0         a woman is holding a banana in her hand   \n",
       "1  a group of sheep in a herd behind a wire fence   \n",
       "2           a cat sitting on side of a television   \n",
       "3            a person standing on top in the snow   \n",
       "4             a man riding a wave off a surfboard   \n",
       "\n",
       "                                             neg4  \n",
       "0      a dancer is holding a dumbbell in her hand  \n",
       "1  a group of sheep in a field under a wire fence  \n",
       "2          a woman sitting on top of a television  \n",
       "3            a person walking on skis in the snow  \n",
       "4           a man riding a bicycle on a surfboard  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Missing Keys: []\n",
      "Unexpected Keys: []\n"
     ]
    }
   ],
   "source": [
    "model, _, image_preprocess = create_model_and_transforms(\n",
    "        \"ViT-B/32\",\n",
    "        \"openai\",\n",
    "        precision=\"amp\",\n",
    "        device=\"cpu\",\n",
    "        jit=False,\n",
    "        force_quick_gelu=False,\n",
    "        pretrained_image=False,\n",
    "        image_mean=None,\n",
    "        image_std=None,\n",
    "        lora=4,\n",
    "        freeze_img=False,\n",
    "        kqv_lora=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisualTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_attn): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ln): Identity()\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_attn): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (ln): Identity()\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint = torch.load(\"logs/exp_name/checkpoints/epoch_5.pt\", map_location=\"cuda:0\")\n",
    "# sd = checkpoint[\"state_dict\"]\n",
    "# if next(iter(sd.items()))[0].startswith(\"module\"):\n",
    "#     sd = {k[len(\"module.\") :]: v for k, v in sd.items()}\n",
    "# model.load_state_dict(sd)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval_scores_single(model, image, positive_caption, negative_caption, device=\"cuda\"):\n",
    "    # Move image to device and compute its embedding\n",
    "    image_embedding = model(image.to(device), None).cpu().detach().numpy()\n",
    "    image_embedding = image_embedding / np.linalg.norm(image_embedding, axis=1, keepdims=True)  # Normalize\n",
    "\n",
    "    # Tokenize and encode the positive caption\n",
    "    positive_tokenized = tokenize(positive_caption)\n",
    "    positive_embedding = model(None, positive_tokenized.to(device)).cpu().detach().numpy()\n",
    "    positive_embedding = positive_embedding / np.linalg.norm(positive_embedding, axis=1, keepdims=True)  # Normalize\n",
    "\n",
    "    # Tokenize and encode the negative caption\n",
    "    negative_tokenized = tokenize(negative_caption)\n",
    "    negative_embedding = model(None, negative_tokenized.to(device)).cpu().detach().numpy()\n",
    "    negative_embedding = negative_embedding / np.linalg.norm(negative_embedding, axis=1, keepdims=True)  # Normalize\n",
    "\n",
    "    # Compute the similarity scores using dot product (cosine similarity)\n",
    "    positive_score = np.dot(image_embedding, positive_embedding.T).item()\n",
    "    negative_score = np.dot(image_embedding, negative_embedding.T).item()\n",
    "\n",
    "    # Return the scores in a dictionary\n",
    "    scores = {\n",
    "        \"positive_score\": positive_score,\n",
    "        \"negative_score\": negative_score\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieval_scores_multiple_negatives(model, image, positive_caption, negative_captions, device=\"cuda\"):\n",
    "    import numpy as np\n",
    "\n",
    "    # Move image to device and compute its embedding\n",
    "    image_embedding = model(image.to(device), None).cpu().detach().numpy()\n",
    "    image_embedding = image_embedding / np.linalg.norm(image_embedding, axis=1, keepdims=True)  # Normalize\n",
    "\n",
    "    # Tokenize and encode the positive caption\n",
    "    positive_tokenized = tokenize(positive_caption)\n",
    "    positive_embedding = model(None, positive_tokenized.to(device)).cpu().detach().numpy()\n",
    "    positive_embedding = positive_embedding / np.linalg.norm(positive_embedding, axis=1, keepdims=True)  # Normalize\n",
    "\n",
    "    # Compute positive score\n",
    "    positive_score = np.dot(image_embedding, positive_embedding.T).item()\n",
    "\n",
    "    # Process each negative caption\n",
    "    negative_scores = {}\n",
    "    for i, negative_caption in enumerate(negative_captions):\n",
    "        # Tokenize and encode the negative caption\n",
    "        negative_tokenized = tokenize(negative_caption)\n",
    "        negative_embedding = model(None, negative_tokenized.to(device)).cpu().detach().numpy()\n",
    "        negative_embedding = negative_embedding / np.linalg.norm(negative_embedding, axis=1, keepdims=True)  # Normalize\n",
    "\n",
    "        # Compute the similarity score\n",
    "        negative_scores[f\"negative_score_{i+1}\"] = np.dot(image_embedding, negative_embedding.T).item()\n",
    "\n",
    "    # Combine scores into a dictionary\n",
    "    scores = {\n",
    "        \"positive_score\": positive_score,\n",
    "        **negative_scores\n",
    "    }\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Preprocesses an image from a file path.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        device (str): Device to move the tensor to (\"cuda\" or \"cpu\").\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Preprocessed image tensor.\n",
    "    \"\"\"\n",
    "    # Define transformations to resize, normalize, and convert to tensor\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to match model input size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load image, apply transformations, and move to device\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image_tensor.to(device)\n",
    "\n",
    "\n",
    "def preprocess_text(caption, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Preprocesses a caption string.\n",
    "    \n",
    "    Args:\n",
    "        caption (str): The text string to be tokenized.\n",
    "        device (str): Device to move the tensor to (\"cuda\" or \"cpu\").\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Tokenized text tensor.\n",
    "    \"\"\"\n",
    "    # Tokenize the caption and convert to tensor\n",
    "    caption_tokenized = tokenize(caption)\n",
    "    return caption_tokenized.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_result(result_dict):\n",
    "    all_scores = list(result_dict.values())\n",
    "\n",
    "    # Sort scores in descending order\n",
    "    sorted_scores = sorted(all_scores, reverse=True)\n",
    "\n",
    "    # Find the rank of the positive score\n",
    "    positive_rank = sorted_scores.index(result_dict['positive_score']) + 1  # +1 for 1-based rank\n",
    "\n",
    "    # Check if the positive score is in top 1 or top 3\n",
    "    is_top1 = positive_rank == 1\n",
    "    is_top3 = positive_rank <= 3\n",
    "    return is_top1, is_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = 0\n",
    "top_3 = 0\n",
    "positive_score = []\n",
    "neg1_score = []\n",
    "neg2_score = []\n",
    "neg3_score = []\n",
    "neg4_score = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    try:\n",
    "        image = preprocess_image(\"/root/autodl-fs/test_images/\"+row.image, device=\"cuda\")\n",
    "        result = get_retrieval_scores_multiple_negatives(model, image, row.positive, [row.neg1, row.neg2, row.neg3, row.neg4])\n",
    "        is_top_1, is_top_3 = score_result(result)\n",
    "        if is_top_1:\n",
    "            top_1 += 1\n",
    "        if is_top_3:\n",
    "            top_3 += 1\n",
    "        positive_score.append(result['positive_score'])\n",
    "        neg1_score.append(result['negative_score_1'])\n",
    "        neg2_score.append(result['negative_score_2'])\n",
    "        neg3_score.append(result['negative_score_3'])\n",
    "        neg4_score.append(result['negative_score_4'])\n",
    "    except Exception as e:\n",
    "        print(idx)\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.323, 0.877)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_1 / 1000, top_3/ 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
